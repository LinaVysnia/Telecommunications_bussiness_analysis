{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import randint, uniform, reciprocal\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SeniorCitizen  Partner  Dependents    tenure  PhoneService  \\\n",
      "0               0        1           0 -1.280248             0   \n",
      "1               0        0           0  0.064303             1   \n",
      "2               0        0           0 -1.239504             1   \n",
      "3               0        0           0  0.512486             0   \n",
      "4               0        0           0 -1.239504             1   \n",
      "5               0        0           0 -0.995040             1   \n",
      "6               0        0           1 -0.424625             1   \n",
      "7               0        0           0 -0.913552             0   \n",
      "8               0        1           0 -0.180161             1   \n",
      "9               0        0           1  1.205134             1   \n",
      "10              0        1           1 -0.791321             1   \n",
      "11              0        0           0 -0.669089             1   \n",
      "12              0        1           0  1.042158             1   \n",
      "13              0        0           0  0.675462             1   \n",
      "14              0        0           0 -0.302393             1   \n",
      "15              0        1           1  1.490341             1   \n",
      "16              0        0           0  0.797694             1   \n",
      "17              0        0           1  1.571829             1   \n",
      "18              0        1           1 -0.913552             1   \n",
      "19              0        0           0 -0.465369             1   \n",
      "\n",
      "    PaperlessBilling  MonthlyCharges  TotalCharges  Male  MultipleLines_No  \\\n",
      "0                  1       -1.161694     -0.994194     0               0.0   \n",
      "1                  0       -0.260878     -0.173740     1               1.0   \n",
      "2                  1       -0.363923     -0.959649     1               1.0   \n",
      "3                  0       -0.747850     -0.195248     1               0.0   \n",
      "4                  1        0.196178     -0.940457     0               1.0   \n",
      "5                  1        1.158489     -0.645369     0               0.0   \n",
      "6                  1        0.807802     -0.147313     1               0.0   \n",
      "7                  0       -1.165018     -0.874169     0               0.0   \n",
      "8                  1        1.329677      0.336516     0               0.0   \n",
      "9                  0       -0.287470      0.531476     1               1.0   \n",
      "10                 1       -0.493561     -0.748188     1               1.0   \n",
      "11                 0       -1.524015     -0.863183     1               1.0   \n",
      "12                 0        1.181757      1.499067     1               0.0   \n",
      "13                 1        1.293113      1.214589     1               0.0   \n",
      "14                 1        1.352946      0.177688     1               1.0   \n",
      "15                 0        1.610559      2.475878     0               0.0   \n",
      "16                 0       -1.467506     -0.556051     0               1.0   \n",
      "17                 0        1.392834      2.249593     1               0.0   \n",
      "18                 0       -0.319049     -0.774262     0               1.0   \n",
      "19                 1        0.839381     -0.185475     0               1.0   \n",
      "\n",
      "    ...  StreamingMovies_No  StreamingMovies_No internet service  \\\n",
      "0   ...                 1.0                                  0.0   \n",
      "1   ...                 1.0                                  0.0   \n",
      "2   ...                 1.0                                  0.0   \n",
      "3   ...                 1.0                                  0.0   \n",
      "4   ...                 1.0                                  0.0   \n",
      "5   ...                 0.0                                  0.0   \n",
      "6   ...                 1.0                                  0.0   \n",
      "7   ...                 1.0                                  0.0   \n",
      "8   ...                 0.0                                  0.0   \n",
      "9   ...                 1.0                                  0.0   \n",
      "10  ...                 1.0                                  0.0   \n",
      "11  ...                 0.0                                  1.0   \n",
      "12  ...                 0.0                                  0.0   \n",
      "13  ...                 0.0                                  0.0   \n",
      "14  ...                 0.0                                  0.0   \n",
      "15  ...                 0.0                                  0.0   \n",
      "16  ...                 0.0                                  1.0   \n",
      "17  ...                 0.0                                  0.0   \n",
      "18  ...                 1.0                                  0.0   \n",
      "19  ...                 0.0                                  0.0   \n",
      "\n",
      "    StreamingMovies_Yes  Contract_Month-to-month  Contract_One year  \\\n",
      "0                   0.0                      1.0                0.0   \n",
      "1                   0.0                      0.0                1.0   \n",
      "2                   0.0                      1.0                0.0   \n",
      "3                   0.0                      0.0                1.0   \n",
      "4                   0.0                      1.0                0.0   \n",
      "5                   1.0                      1.0                0.0   \n",
      "6                   0.0                      1.0                0.0   \n",
      "7                   0.0                      1.0                0.0   \n",
      "8                   1.0                      1.0                0.0   \n",
      "9                   0.0                      0.0                1.0   \n",
      "10                  0.0                      1.0                0.0   \n",
      "11                  0.0                      0.0                0.0   \n",
      "12                  1.0                      0.0                1.0   \n",
      "13                  1.0                      1.0                0.0   \n",
      "14                  1.0                      1.0                0.0   \n",
      "15                  1.0                      0.0                0.0   \n",
      "16                  0.0                      0.0                1.0   \n",
      "17                  1.0                      0.0                0.0   \n",
      "18                  0.0                      1.0                0.0   \n",
      "19                  1.0                      1.0                0.0   \n",
      "\n",
      "    Contract_Two year  PaymentMethod_Bank transfer (automatic)  \\\n",
      "0                 0.0                                      0.0   \n",
      "1                 0.0                                      0.0   \n",
      "2                 0.0                                      0.0   \n",
      "3                 0.0                                      1.0   \n",
      "4                 0.0                                      0.0   \n",
      "5                 0.0                                      0.0   \n",
      "6                 0.0                                      0.0   \n",
      "7                 0.0                                      0.0   \n",
      "8                 0.0                                      0.0   \n",
      "9                 0.0                                      1.0   \n",
      "10                0.0                                      0.0   \n",
      "11                1.0                                      0.0   \n",
      "12                0.0                                      0.0   \n",
      "13                0.0                                      1.0   \n",
      "14                0.0                                      0.0   \n",
      "15                1.0                                      0.0   \n",
      "16                0.0                                      0.0   \n",
      "17                1.0                                      1.0   \n",
      "18                0.0                                      0.0   \n",
      "19                0.0                                      0.0   \n",
      "\n",
      "    PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
      "0                                     0.0                             1.0   \n",
      "1                                     0.0                             0.0   \n",
      "2                                     0.0                             0.0   \n",
      "3                                     0.0                             0.0   \n",
      "4                                     0.0                             1.0   \n",
      "5                                     0.0                             1.0   \n",
      "6                                     1.0                             0.0   \n",
      "7                                     0.0                             0.0   \n",
      "8                                     0.0                             1.0   \n",
      "9                                     0.0                             0.0   \n",
      "10                                    0.0                             0.0   \n",
      "11                                    1.0                             0.0   \n",
      "12                                    1.0                             0.0   \n",
      "13                                    0.0                             0.0   \n",
      "14                                    0.0                             1.0   \n",
      "15                                    1.0                             0.0   \n",
      "16                                    0.0                             0.0   \n",
      "17                                    0.0                             0.0   \n",
      "18                                    1.0                             0.0   \n",
      "19                                    0.0                             1.0   \n",
      "\n",
      "    PaymentMethod_Mailed check  \n",
      "0                          0.0  \n",
      "1                          1.0  \n",
      "2                          1.0  \n",
      "3                          0.0  \n",
      "4                          0.0  \n",
      "5                          0.0  \n",
      "6                          0.0  \n",
      "7                          1.0  \n",
      "8                          0.0  \n",
      "9                          0.0  \n",
      "10                         1.0  \n",
      "11                         0.0  \n",
      "12                         0.0  \n",
      "13                         0.0  \n",
      "14                         0.0  \n",
      "15                         0.0  \n",
      "16                         1.0  \n",
      "17                         0.0  \n",
      "18                         0.0  \n",
      "19                         0.0  \n",
      "\n",
      "[20 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "#Decision tree would handle all the dimensionality pretty well\n",
    "df = pd.read_csv(\"Customer-numerical_raw.csv\")\n",
    "\n",
    "results = df.pop(\"Churn\")\n",
    "\n",
    "features_to_scale = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "scaler = StandardScaler()\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "print(df.head(20))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, results, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree Model:  DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=2,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#Decision tree prediction model\n",
    "#Finding best params\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5, 6, 7 ,8 ,9],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(dt, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_dt = grid.best_estimator_\n",
    "\n",
    "print(\"Best Decision Tree Model: \", best_dt)\n",
    "\n",
    "# #test 1 using f1\n",
    "# best_dt = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=2,random_state=42)\n",
    "# # Accuracy: 0.7739872068230277\n",
    "# # F1-score: 0.7756494893324082\n",
    "\n",
    "# #test 2 using accuracy\n",
    "# #best_dt = DecisionTreeClassifier(max_depth=6, min_samples_leaf=2, random_state=42)\n",
    "# # Accuracy: 0.7732764747690121\n",
    "# # F1-score: 0.7725883751066696\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7739872068230277\n",
      "F1-score: 0.7756494893324082\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "\n",
    "best_dt = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=2,random_state=42)\n",
    "\n",
    "best_dt.fit(X_train, y_train)\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[246], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# Number of random combinations to try (adjust this)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(rf, param_distributions, n_iter\u001b[38;5;241m=\u001b[39mn_iter, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_rf)\n",
      "File \u001b[1;32mc:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1951\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1953\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Random forest prediction model\n",
    "#Finding best params\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 200),  # Randomly sample between 50 and 200\n",
    "    'max_depth': [10,20,30,40,50], # None or random integer between 10 and 50\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "n_iter = 100  # Number of random combinations to try (adjust this)\n",
    "random_search = RandomizedSearchCV(rf, param_distributions, n_iter=n_iter, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = random_search.best_estimator_\n",
    "print(best_rf)\n",
    "\n",
    "#Test 1\n",
    "#best_rf = RandomForestClassifier(class_weight='balanced', max_depth=np.int64(39),\n",
    "#          max_features='log2', min_samples_leaf=4,min_samples_split=3, n_estimators=148, random_state=42)\n",
    "# Accuracy: 0.7540867093105899\n",
    "# F1-score: 0.7635032080257796\n",
    "\n",
    "#test 2 \n",
    "# RandomForestClassifier(class_weight='balanced_subsample', max_depth=10,\n",
    "#                        max_features='log2', min_samples_leaf=4,\n",
    "#                        min_samples_split=8, n_estimators=62, random_state=42)\n",
    "# Accuracy: 0.7491115849324804\n",
    "# F1-score: 0.760556945261212\n",
    "\n",
    "#test 3\n",
    "# RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
    "#                        max_depth=10, max_features='log2', min_samples_leaf=3,\n",
    "#                        min_samples_split=4, n_estimators=171, random_state=42)\n",
    "# Accuracy: 0.7469793887704336\n",
    "# F1-score: 0.7582071482471747\n",
    "\n",
    "#test 4\n",
    "# RandomForestClassifier(class_weight='balanced', max_depth=10,\n",
    "#                        min_samples_leaf=3, min_samples_split=7, n_estimators=95,\n",
    "#                        random_state=42)\n",
    "# Accuracy: 0.7533759772565742\n",
    "# F1-score: 0.7639969459369599\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7547974413646056\n",
      "F1-score: 0.7641317180460944\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "best_rf = RandomForestClassifier(class_weight='balanced', max_depth=np.int64(39),\n",
    "          max_features='log2', min_samples_leaf=4,min_samples_split=3, n_estimators=148, random_state=42)\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "SVC(C=np.float64(1.318174530710419), class_weight='balanced', random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#Support vector machine model\n",
    "#Finding best params\n",
    "\n",
    "param_distributions = {\n",
    "    'C': reciprocal(1, 100),  # Reduced range for C (1 to 100) - MOST IMPORTANT\n",
    "    'kernel': ['rbf'],  # Focus on rbf kernel initially - VERY IMPORTANT\n",
    "    'gamma': ['scale', 'auto'] + list(reciprocal(0.001, 0.1).rvs(5)),  # Reduced range and fewer samples for gamma - IMPORTANT\n",
    "    'class_weight': [None, 'balanced']  # Keep class_weight, but it's less computationally intensive\n",
    "}\n",
    "svc = SVC(random_state=42)\n",
    "\n",
    "n_iter = 100  \n",
    "random_search = RandomizedSearchCV(svc, param_distributions, n_iter=n_iter, cv=5, scoring='f1', n_jobs=-1, verbose=1)  # Use F1-score for classification\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_svc = random_search.best_estimator_\n",
    "print(best_svc)\n",
    "\n",
    "#test 1\n",
    "#best_svc = SVC(C=np.float64(1.309057363357464), class_weight='balanced',\n",
    "#     gamma=np.float64(0.023141125053224965), random_state=42)\n",
    "# Accuracy: 0.7334754797441365\n",
    "# Best F1-score: 0.6275991221199372\n",
    "\n",
    "#test 2\n",
    "#best_svc = SVC(C=np.float64(1.1332667250594013), class_weight='balanced', random_state=42)\n",
    "# Accuracy: 0.7327647476901208\n",
    "# Best F1-score: 0.6266565410903586\n",
    "\n",
    "#test 3\n",
    "#best_svc = SVC(C=np.float64(1.318174530710419), class_weight='balanced', random_state=42)\n",
    "#Accuracy: 0.7356076759061834\n",
    "#Best F1-score: 0.7491993297100363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC Model:  SVC(C=np.float64(1.318174530710419), class_weight='balanced', random_state=42)\n",
      "Accuracy: 0.7356076759061834\n",
      "Best F1-score: 0.7491993297100363\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "best_svc = SVC(C=np.float64(1.318174530710419), class_weight='balanced', random_state=42)\n",
    "\n",
    "best_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_svc.predict(X_test)\n",
    "\n",
    "print(\"Best SVC Model: \", best_svc)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Best F1-score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "280 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3328838475629627) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.5667938041552734) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2939342407008252) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.1752469697684278) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.1624571421089511) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2488323704112245) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.066541969569653) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3961801537745573) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.5896225404516509) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.168663439743963) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.570632328764498) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2885751187060919) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2289030303758786) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.0249543482936925) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3056908121761976) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4006420827874901) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.0955814946652747) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.1783019137582293) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3383812719683508) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2626527556271694) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4833037599486412) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.421707241948043) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3832167133445927) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3953436466724232) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.201635497062954) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.5106223369534888) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4563235458786428) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3475435079683475) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.5166962643895228) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2576870699345586) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2181684062495435) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.5307888125894322) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.0270414170625815) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2684915256706866) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.36828270178872) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.1358513330084634) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3131860496087413) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.1213394851688991) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3761206511368456) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.469232844750863) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2282132917496904) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4379610431757728) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.3754870369355117) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4522789037098138) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4910494033707204) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.332438234073046) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2052802996249112) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2889839154208453) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.2728599766205853) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4836744216037978) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.0019059748434567) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.0853275495891541) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4703418084721975) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4444066942095475) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.0879614490569358) instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'subsample' parameter of GradientBoostingClassifier must be a float in the range (0.0, 1.0]. Got np.float64(1.4673309318811638) instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.56143306        nan        nan        nan 0.56810089        nan\n",
      "        nan        nan        nan 0.59265859        nan        nan\n",
      "        nan 0.56733818        nan        nan 0.57299701 0.57763837\n",
      "        nan 0.56982207 0.58503974 0.55179568        nan        nan\n",
      " 0.5483414  0.55242408        nan 0.60061172 0.59971966        nan\n",
      "        nan        nan        nan        nan        nan 0.55706805\n",
      " 0.57269672 0.55331105        nan 0.58919552        nan        nan\n",
      "        nan 0.58427831 0.5516464  0.56447512        nan 0.56650978\n",
      "        nan 0.550303          nan        nan 0.59405273        nan\n",
      "        nan        nan 0.5970865         nan        nan 0.58304244\n",
      " 0.54133081 0.55476344 0.58781425        nan 0.55810092        nan\n",
      " 0.57373474 0.58928269        nan        nan 0.54317613        nan\n",
      "        nan 0.59428936        nan        nan 0.58262108        nan\n",
      "        nan        nan        nan        nan        nan 0.59790692\n",
      "        nan        nan 0.58297661        nan 0.56339529        nan\n",
      " 0.58917954 0.55150662 0.59515034        nan 0.54330453 0.55481297\n",
      " 0.56154899        nan 0.57643087        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(learning_rate=np.float64(0.09433390791067263),\n",
      "                           max_depth=5, max_features='log2', min_samples_leaf=4,\n",
      "                           min_samples_split=12, n_estimators=64,\n",
      "                           random_state=42,\n",
      "                           subsample=np.float64(0.638495604061242))\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosting classifier model\n",
    "#Finding best params\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 300),  # Number of boosting stages (trees)\n",
    "    'learning_rate': uniform(0.01, 0.3),  # Contribution of each tree\n",
    "    'max_depth': randint(3, 10),  # Maximum depth of the individual trees\n",
    "    'min_samples_split': randint(2, 20),  # Minimum samples to split a node\n",
    "    'min_samples_leaf': randint(1, 10),  # Minimum samples in a leaf\n",
    "    'subsample': uniform(0.6, 1.0),  # Fraction of samples used for fitting the trees\n",
    "    'max_features': ['sqrt', 'log2', None],  # Number of features to consider for splits\n",
    "    'criterion': ['friedman_mse', 'squared_error'], # Function to measure the quality of a split.\n",
    "}\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "n_iter = 100 \n",
    "random_search = RandomizedSearchCV(gb_clf, param_distributions, n_iter=n_iter, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_gb_clf = random_search.best_estimator_\n",
    "print(best_gb_clf)\n",
    "\n",
    "#test 1\n",
    "# Best Gradient Boosting Classifier: GradientBoostingClassifier(criterion='squared_error',\n",
    "#                            learning_rate=np.float64(0.03307275938883212),\n",
    "#                            max_depth=4, min_samples_leaf=2, min_samples_split=3,\n",
    "#                            n_estimators=195, random_state=42,\n",
    "#                            subsample=np.float64(0.9823357224951418))\n",
    "# Best F1-score: 0.5972449377862121\n",
    "\n",
    "#test 2\n",
    "# Best Gradient Boosting Classifier: \n",
    "# GradientBoostingClassifier(learning_rate=np.float64(0.047628255111097854),\n",
    "#                            max_depth=4, max_features='log2', min_samples_leaf=9,\n",
    "#                            n_estimators=156, random_state=42,\n",
    "#                            subsample=np.float64(0.6836865782688305))\n",
    "# Best F1-score: 0.5982972141243003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting Classifier: GradientBoostingClassifier(learning_rate=np.float64(0.047628255111097854),\n",
      "                           max_depth=4, max_features='log2', min_samples_leaf=9,\n",
      "                           n_estimators=156, random_state=42,\n",
      "                           subsample=np.float64(0.6836865782688305))\n",
      "Accuracy: 0.7867803837953091\n",
      "Best F1-score: 0.7785059297350782\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "best_gb_clf = GradientBoostingClassifier(learning_rate=np.float64(0.047628255111097854),\n",
    "                           max_depth=4, max_features='log2', min_samples_leaf=9,\n",
    "                           n_estimators=156, random_state=42,\n",
    "                           subsample=np.float64(0.6836865782688305))\n",
    "\n",
    "best_gb_clf.fit(X_train, y_train)\n",
    "y_pred = best_gb_clf.predict(X_test)\n",
    "\n",
    "print(\"Best Gradient Boosting Classifier:\", best_gb_clf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Best F1-score:\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "width = X_train.shape[1]\n",
    "\n",
    "model.add(Input(shape=(width,)))  #gonna give the same amount of inputs as parameters. Why tuple?\n",
    "\n",
    "# #first hidden layer\n",
    "# model.add(Dense(units=4, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(units=64, activation=\"relu\"))\n",
    "model.add(Dropout(rate=0.3))\n",
    "\n",
    "#second hidden layer\n",
    "model.add(Dense(units=32, activation=\"relu\")) #try 16 or 32\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(units=16, activation=\"relu\")) #try 16 or 32\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(units=8, activation=\"relu\")) #try 16 or 32\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "model.add(Dense(units=4, activation=\"relu\")) #try 16 or 32\n",
    "model.add(Dropout(rate=0.2))\n",
    "\n",
    "#try:\n",
    "#neuron count\n",
    "#architecture piltuveli pabandyti (64, 32, 16)...\n",
    "\n",
    "#final output layer\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))  # 1 with sigmoid should lean towards 0 or 1 just the binary classification we want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.00001\n",
    "batch_size = 32 #try 32 and 128\n",
    "epochs = 500\n",
    "validation_split = 0.1\n",
    "# Add early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = 'binary_crossentropy', #as we want a binary output\n",
    "    metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5234 - loss: 0.6992 - val_accuracy: 0.4618 - val_loss: 0.7004\n",
      "Epoch 2/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5484 - loss: 0.6962 - val_accuracy: 0.5098 - val_loss: 0.6952\n",
      "Epoch 3/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5490 - loss: 0.6940 - val_accuracy: 0.5755 - val_loss: 0.6893\n",
      "Epoch 4/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5730 - loss: 0.6861 - val_accuracy: 0.6252 - val_loss: 0.6837\n",
      "Epoch 5/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5913 - loss: 0.6816 - val_accuracy: 0.6750 - val_loss: 0.6780\n",
      "Epoch 6/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6075 - loss: 0.6807 - val_accuracy: 0.7016 - val_loss: 0.6728\n",
      "Epoch 7/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6137 - loss: 0.6770 - val_accuracy: 0.7105 - val_loss: 0.6672\n",
      "Epoch 8/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6408 - loss: 0.6671 - val_accuracy: 0.7229 - val_loss: 0.6609\n",
      "Epoch 9/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6341 - loss: 0.6600 - val_accuracy: 0.7300 - val_loss: 0.6547\n",
      "Epoch 10/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6455 - loss: 0.6605 - val_accuracy: 0.7336 - val_loss: 0.6484\n",
      "Epoch 11/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6378 - loss: 0.6625 - val_accuracy: 0.7336 - val_loss: 0.6419\n",
      "Epoch 12/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6584 - loss: 0.6512 - val_accuracy: 0.7336 - val_loss: 0.6351\n",
      "Epoch 13/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6538 - loss: 0.6507 - val_accuracy: 0.7336 - val_loss: 0.6287\n",
      "Epoch 14/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6535 - loss: 0.6460 - val_accuracy: 0.7336 - val_loss: 0.6222\n",
      "Epoch 15/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6773 - loss: 0.6416 - val_accuracy: 0.7336 - val_loss: 0.6158\n",
      "Epoch 16/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6726 - loss: 0.6323 - val_accuracy: 0.7336 - val_loss: 0.6096\n",
      "Epoch 17/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6990 - loss: 0.6197 - val_accuracy: 0.7336 - val_loss: 0.6034\n",
      "Epoch 18/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6865 - loss: 0.6251 - val_accuracy: 0.7336 - val_loss: 0.5977\n",
      "Epoch 19/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6965 - loss: 0.6207 - val_accuracy: 0.7336 - val_loss: 0.5925\n",
      "Epoch 20/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6882 - loss: 0.6234 - val_accuracy: 0.7336 - val_loss: 0.5872\n",
      "Epoch 21/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6961 - loss: 0.6193 - val_accuracy: 0.7336 - val_loss: 0.5820\n",
      "Epoch 22/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7026 - loss: 0.6072 - val_accuracy: 0.7336 - val_loss: 0.5772\n",
      "Epoch 23/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6994 - loss: 0.6061 - val_accuracy: 0.7336 - val_loss: 0.5727\n",
      "Epoch 24/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7020 - loss: 0.6108 - val_accuracy: 0.7336 - val_loss: 0.5683\n",
      "Epoch 25/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7011 - loss: 0.5991 - val_accuracy: 0.7336 - val_loss: 0.5646\n",
      "Epoch 26/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6971 - loss: 0.6110 - val_accuracy: 0.7336 - val_loss: 0.5615\n",
      "Epoch 27/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7060 - loss: 0.6067 - val_accuracy: 0.7336 - val_loss: 0.5586\n",
      "Epoch 28/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6955 - loss: 0.6065 - val_accuracy: 0.7336 - val_loss: 0.5558\n",
      "Epoch 29/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6946 - loss: 0.6073 - val_accuracy: 0.7336 - val_loss: 0.5531\n",
      "Epoch 30/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7086 - loss: 0.5983 - val_accuracy: 0.7336 - val_loss: 0.5508\n",
      "Epoch 31/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7138 - loss: 0.5947 - val_accuracy: 0.7336 - val_loss: 0.5475\n",
      "Epoch 32/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7088 - loss: 0.5878 - val_accuracy: 0.7336 - val_loss: 0.5444\n",
      "Epoch 33/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7075 - loss: 0.5911 - val_accuracy: 0.7336 - val_loss: 0.5414\n",
      "Epoch 34/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7081 - loss: 0.5787 - val_accuracy: 0.7336 - val_loss: 0.5383\n",
      "Epoch 35/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7117 - loss: 0.5846 - val_accuracy: 0.7336 - val_loss: 0.5355\n",
      "Epoch 36/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7160 - loss: 0.5788 - val_accuracy: 0.7336 - val_loss: 0.5331\n",
      "Epoch 37/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7184 - loss: 0.5841 - val_accuracy: 0.7336 - val_loss: 0.5303\n",
      "Epoch 38/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7095 - loss: 0.5724 - val_accuracy: 0.7336 - val_loss: 0.5276\n",
      "Epoch 39/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7029 - loss: 0.5894 - val_accuracy: 0.7336 - val_loss: 0.5259\n",
      "Epoch 40/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7198 - loss: 0.5703 - val_accuracy: 0.7336 - val_loss: 0.5232\n",
      "Epoch 41/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.5646 - val_accuracy: 0.7336 - val_loss: 0.5206\n",
      "Epoch 42/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7052 - loss: 0.5776 - val_accuracy: 0.7336 - val_loss: 0.5182\n",
      "Epoch 43/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.5620 - val_accuracy: 0.7336 - val_loss: 0.5158\n",
      "Epoch 44/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.5589 - val_accuracy: 0.7336 - val_loss: 0.5135\n",
      "Epoch 45/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7135 - loss: 0.5751 - val_accuracy: 0.7336 - val_loss: 0.5118\n",
      "Epoch 46/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7166 - loss: 0.5655 - val_accuracy: 0.7336 - val_loss: 0.5098\n",
      "Epoch 47/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.5499 - val_accuracy: 0.7336 - val_loss: 0.5078\n",
      "Epoch 48/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7095 - loss: 0.5570 - val_accuracy: 0.7336 - val_loss: 0.5062\n",
      "Epoch 49/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7114 - loss: 0.5593 - val_accuracy: 0.7336 - val_loss: 0.5046\n",
      "Epoch 50/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7159 - loss: 0.5598 - val_accuracy: 0.7336 - val_loss: 0.5027\n",
      "Epoch 51/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.5484 - val_accuracy: 0.7336 - val_loss: 0.5007\n",
      "Epoch 52/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7144 - loss: 0.5615 - val_accuracy: 0.7336 - val_loss: 0.4991\n",
      "Epoch 53/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7111 - loss: 0.5552 - val_accuracy: 0.7336 - val_loss: 0.4974\n",
      "Epoch 54/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7156 - loss: 0.5619 - val_accuracy: 0.7336 - val_loss: 0.4958\n",
      "Epoch 55/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7216 - loss: 0.5516 - val_accuracy: 0.7336 - val_loss: 0.4940\n",
      "Epoch 56/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7176 - loss: 0.5531 - val_accuracy: 0.7336 - val_loss: 0.4930\n",
      "Epoch 57/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7171 - loss: 0.5515 - val_accuracy: 0.7336 - val_loss: 0.4906\n",
      "Epoch 58/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7186 - loss: 0.5620 - val_accuracy: 0.7336 - val_loss: 0.4896\n",
      "Epoch 59/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7172 - loss: 0.5506 - val_accuracy: 0.7336 - val_loss: 0.4881\n",
      "Epoch 60/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7118 - loss: 0.5652 - val_accuracy: 0.7336 - val_loss: 0.4871\n",
      "Epoch 61/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.5429 - val_accuracy: 0.7336 - val_loss: 0.4855\n",
      "Epoch 62/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7303 - loss: 0.5525 - val_accuracy: 0.7336 - val_loss: 0.4844\n",
      "Epoch 63/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7163 - loss: 0.5527 - val_accuracy: 0.7336 - val_loss: 0.4835\n",
      "Epoch 64/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.5410 - val_accuracy: 0.7336 - val_loss: 0.4823\n",
      "Epoch 65/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5432 - val_accuracy: 0.7336 - val_loss: 0.4809\n",
      "Epoch 66/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7126 - loss: 0.5498 - val_accuracy: 0.7336 - val_loss: 0.4800\n",
      "Epoch 67/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7152 - loss: 0.5472 - val_accuracy: 0.7336 - val_loss: 0.4788\n",
      "Epoch 68/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.5492 - val_accuracy: 0.7336 - val_loss: 0.4780\n",
      "Epoch 69/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.5390 - val_accuracy: 0.7336 - val_loss: 0.4774\n",
      "Epoch 70/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7071 - loss: 0.5633 - val_accuracy: 0.7336 - val_loss: 0.4773\n",
      "Epoch 71/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.5368 - val_accuracy: 0.7336 - val_loss: 0.4764\n",
      "Epoch 72/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7241 - loss: 0.5402 - val_accuracy: 0.7336 - val_loss: 0.4750\n",
      "Epoch 73/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.5501 - val_accuracy: 0.7336 - val_loss: 0.4744\n",
      "Epoch 74/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7198 - loss: 0.5400 - val_accuracy: 0.7336 - val_loss: 0.4738\n",
      "Epoch 75/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7215 - loss: 0.5474 - val_accuracy: 0.7336 - val_loss: 0.4731\n",
      "Epoch 76/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 0.5388 - val_accuracy: 0.7336 - val_loss: 0.4725\n",
      "Epoch 77/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.5377 - val_accuracy: 0.7336 - val_loss: 0.4719\n",
      "Epoch 78/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7119 - loss: 0.5469 - val_accuracy: 0.7336 - val_loss: 0.4715\n",
      "Epoch 79/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5445 - val_accuracy: 0.7336 - val_loss: 0.4709\n",
      "Epoch 80/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7131 - loss: 0.5426 - val_accuracy: 0.7336 - val_loss: 0.4697\n",
      "Epoch 81/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7149 - loss: 0.5433 - val_accuracy: 0.7336 - val_loss: 0.4692\n",
      "Epoch 82/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7193 - loss: 0.5347 - val_accuracy: 0.7336 - val_loss: 0.4687\n",
      "Epoch 83/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7288 - loss: 0.5368 - val_accuracy: 0.7336 - val_loss: 0.4678\n",
      "Epoch 84/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7205 - loss: 0.5416 - val_accuracy: 0.7336 - val_loss: 0.4672\n",
      "Epoch 85/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7237 - loss: 0.5364 - val_accuracy: 0.7336 - val_loss: 0.4668\n",
      "Epoch 86/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7319 - loss: 0.5235 - val_accuracy: 0.7336 - val_loss: 0.4658\n",
      "Epoch 87/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.5265 - val_accuracy: 0.7336 - val_loss: 0.4652\n",
      "Epoch 88/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7228 - loss: 0.5394 - val_accuracy: 0.7336 - val_loss: 0.4649\n",
      "Epoch 89/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.5304 - val_accuracy: 0.7336 - val_loss: 0.4648\n",
      "Epoch 90/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7173 - loss: 0.5354 - val_accuracy: 0.7336 - val_loss: 0.4644\n",
      "Epoch 91/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5264 - val_accuracy: 0.7336 - val_loss: 0.4635\n",
      "Epoch 92/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7268 - loss: 0.5322 - val_accuracy: 0.7336 - val_loss: 0.4628\n",
      "Epoch 93/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7211 - loss: 0.5297 - val_accuracy: 0.7336 - val_loss: 0.4624\n",
      "Epoch 94/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7266 - loss: 0.5306 - val_accuracy: 0.7336 - val_loss: 0.4612\n",
      "Epoch 95/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.5301 - val_accuracy: 0.7336 - val_loss: 0.4610\n",
      "Epoch 96/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.5314 - val_accuracy: 0.7336 - val_loss: 0.4608\n",
      "Epoch 97/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7228 - loss: 0.5383 - val_accuracy: 0.7336 - val_loss: 0.4605\n",
      "Epoch 98/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7261 - loss: 0.5388 - val_accuracy: 0.7336 - val_loss: 0.4603\n",
      "Epoch 99/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.5416 - val_accuracy: 0.7336 - val_loss: 0.4600\n",
      "Epoch 100/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7261 - loss: 0.5340 - val_accuracy: 0.7336 - val_loss: 0.4594\n",
      "Epoch 101/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5157 - val_accuracy: 0.7336 - val_loss: 0.4588\n",
      "Epoch 102/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7232 - loss: 0.5339 - val_accuracy: 0.7336 - val_loss: 0.4586\n",
      "Epoch 103/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7218 - loss: 0.5380 - val_accuracy: 0.7336 - val_loss: 0.4587\n",
      "Epoch 104/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7218 - loss: 0.5184 - val_accuracy: 0.7336 - val_loss: 0.4581\n",
      "Epoch 105/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.5277 - val_accuracy: 0.7336 - val_loss: 0.4573\n",
      "Epoch 106/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7255 - loss: 0.5274 - val_accuracy: 0.7336 - val_loss: 0.4569\n",
      "Epoch 107/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7143 - loss: 0.5391 - val_accuracy: 0.7336 - val_loss: 0.4565\n",
      "Epoch 108/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7284 - loss: 0.5367 - val_accuracy: 0.7336 - val_loss: 0.4567\n",
      "Epoch 109/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5231 - val_accuracy: 0.7336 - val_loss: 0.4562\n",
      "Epoch 110/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7101 - loss: 0.5430 - val_accuracy: 0.7336 - val_loss: 0.4556\n",
      "Epoch 111/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7210 - loss: 0.5230 - val_accuracy: 0.7336 - val_loss: 0.4552\n",
      "Epoch 112/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.5245 - val_accuracy: 0.7336 - val_loss: 0.4547\n",
      "Epoch 113/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7217 - loss: 0.5251 - val_accuracy: 0.7336 - val_loss: 0.4543\n",
      "Epoch 114/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.5313 - val_accuracy: 0.7336 - val_loss: 0.4541\n",
      "Epoch 115/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7375 - loss: 0.5209 - val_accuracy: 0.7336 - val_loss: 0.4538\n",
      "Epoch 116/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.5187 - val_accuracy: 0.7336 - val_loss: 0.4538\n",
      "Epoch 117/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.5133 - val_accuracy: 0.7336 - val_loss: 0.4533\n",
      "Epoch 118/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.5261 - val_accuracy: 0.7336 - val_loss: 0.4530\n",
      "Epoch 119/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.5125 - val_accuracy: 0.7336 - val_loss: 0.4525\n",
      "Epoch 120/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.5167 - val_accuracy: 0.7336 - val_loss: 0.4518\n",
      "Epoch 121/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5220 - val_accuracy: 0.7336 - val_loss: 0.4516\n",
      "Epoch 122/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.5236 - val_accuracy: 0.7336 - val_loss: 0.4519\n",
      "Epoch 123/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7138 - loss: 0.5333 - val_accuracy: 0.7336 - val_loss: 0.4512\n",
      "Epoch 124/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5225 - val_accuracy: 0.7336 - val_loss: 0.4510\n",
      "Epoch 125/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.5225 - val_accuracy: 0.7336 - val_loss: 0.4510\n",
      "Epoch 126/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7213 - loss: 0.5191 - val_accuracy: 0.7336 - val_loss: 0.4509\n",
      "Epoch 127/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7355 - loss: 0.5231 - val_accuracy: 0.7336 - val_loss: 0.4507\n",
      "Epoch 128/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7232 - loss: 0.5224 - val_accuracy: 0.7336 - val_loss: 0.4509\n",
      "Epoch 129/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7379 - loss: 0.5259 - val_accuracy: 0.7336 - val_loss: 0.4510\n",
      "Epoch 130/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7275 - loss: 0.5314 - val_accuracy: 0.7336 - val_loss: 0.4510\n",
      "Epoch 131/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5254 - val_accuracy: 0.7336 - val_loss: 0.4511\n",
      "Epoch 132/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.5033 - val_accuracy: 0.7336 - val_loss: 0.4506\n",
      "Epoch 133/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7318 - loss: 0.5258 - val_accuracy: 0.7336 - val_loss: 0.4505\n",
      "Epoch 134/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.5321 - val_accuracy: 0.7336 - val_loss: 0.4500\n",
      "Epoch 135/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7294 - loss: 0.5317 - val_accuracy: 0.7336 - val_loss: 0.4499\n",
      "Epoch 136/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7273 - loss: 0.5231 - val_accuracy: 0.7336 - val_loss: 0.4499\n",
      "Epoch 137/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7379 - loss: 0.5176 - val_accuracy: 0.7336 - val_loss: 0.4493\n",
      "Epoch 138/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5229 - val_accuracy: 0.7336 - val_loss: 0.4496\n",
      "Epoch 139/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7232 - loss: 0.5288 - val_accuracy: 0.7336 - val_loss: 0.4494\n",
      "Epoch 140/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7186 - loss: 0.5334 - val_accuracy: 0.7336 - val_loss: 0.4490\n",
      "Epoch 141/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7225 - loss: 0.5197 - val_accuracy: 0.7336 - val_loss: 0.4485\n",
      "Epoch 142/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.5161 - val_accuracy: 0.7336 - val_loss: 0.4476\n",
      "Epoch 143/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7296 - loss: 0.5265 - val_accuracy: 0.7336 - val_loss: 0.4473\n",
      "Epoch 144/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5228 - val_accuracy: 0.7336 - val_loss: 0.4473\n",
      "Epoch 145/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.5204 - val_accuracy: 0.7336 - val_loss: 0.4472\n",
      "Epoch 146/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5128 - val_accuracy: 0.7336 - val_loss: 0.4470\n",
      "Epoch 147/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7233 - loss: 0.5395 - val_accuracy: 0.7336 - val_loss: 0.4468\n",
      "Epoch 148/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.5204 - val_accuracy: 0.7336 - val_loss: 0.4469\n",
      "Epoch 149/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7271 - loss: 0.5209 - val_accuracy: 0.7336 - val_loss: 0.4464\n",
      "Epoch 150/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.5256 - val_accuracy: 0.7336 - val_loss: 0.4463\n",
      "Epoch 151/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 0.5300 - val_accuracy: 0.7336 - val_loss: 0.4462\n",
      "Epoch 152/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7238 - loss: 0.5357 - val_accuracy: 0.7336 - val_loss: 0.4462\n",
      "Epoch 153/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7240 - loss: 0.5171 - val_accuracy: 0.7336 - val_loss: 0.4458\n",
      "Epoch 154/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5164 - val_accuracy: 0.7336 - val_loss: 0.4457\n",
      "Epoch 155/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.5188 - val_accuracy: 0.7336 - val_loss: 0.4456\n",
      "Epoch 156/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7249 - loss: 0.5306 - val_accuracy: 0.7336 - val_loss: 0.4454\n",
      "Epoch 157/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.5169 - val_accuracy: 0.7336 - val_loss: 0.4451\n",
      "Epoch 158/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.5218 - val_accuracy: 0.7336 - val_loss: 0.4449\n",
      "Epoch 159/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.5210 - val_accuracy: 0.7336 - val_loss: 0.4450\n",
      "Epoch 160/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7275 - loss: 0.5120 - val_accuracy: 0.7336 - val_loss: 0.4448\n",
      "Epoch 161/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7187 - loss: 0.5174 - val_accuracy: 0.7336 - val_loss: 0.4441\n",
      "Epoch 162/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.5158 - val_accuracy: 0.7336 - val_loss: 0.4437\n",
      "Epoch 163/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.5159 - val_accuracy: 0.7336 - val_loss: 0.4432\n",
      "Epoch 164/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.5234 - val_accuracy: 0.7336 - val_loss: 0.4430\n",
      "Epoch 165/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5025 - val_accuracy: 0.7336 - val_loss: 0.4429\n",
      "Epoch 166/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7442 - loss: 0.5151 - val_accuracy: 0.7336 - val_loss: 0.4431\n",
      "Epoch 167/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7288 - loss: 0.5076 - val_accuracy: 0.7336 - val_loss: 0.4429\n",
      "Epoch 168/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.5177 - val_accuracy: 0.7336 - val_loss: 0.4428\n",
      "Epoch 169/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5169 - val_accuracy: 0.7336 - val_loss: 0.4429\n",
      "Epoch 170/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.5264 - val_accuracy: 0.7336 - val_loss: 0.4435\n",
      "Epoch 171/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7253 - loss: 0.5226 - val_accuracy: 0.7336 - val_loss: 0.4433\n",
      "Epoch 172/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.5250 - val_accuracy: 0.7336 - val_loss: 0.4433\n",
      "Epoch 173/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.5204 - val_accuracy: 0.7336 - val_loss: 0.4432\n",
      "Epoch 174/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.4956 - val_accuracy: 0.7336 - val_loss: 0.4426\n",
      "Epoch 175/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5196 - val_accuracy: 0.7336 - val_loss: 0.4429\n",
      "Epoch 176/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.5063 - val_accuracy: 0.7336 - val_loss: 0.4426\n",
      "Epoch 177/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.5056 - val_accuracy: 0.7336 - val_loss: 0.4424\n",
      "Epoch 178/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.5087 - val_accuracy: 0.7336 - val_loss: 0.4422\n",
      "Epoch 179/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7324 - loss: 0.5142 - val_accuracy: 0.7336 - val_loss: 0.4420\n",
      "Epoch 180/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.5174 - val_accuracy: 0.7336 - val_loss: 0.4420\n",
      "Epoch 181/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.5115 - val_accuracy: 0.7336 - val_loss: 0.4421\n",
      "Epoch 182/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7280 - loss: 0.5163 - val_accuracy: 0.7336 - val_loss: 0.4419\n",
      "Epoch 183/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5168 - val_accuracy: 0.7336 - val_loss: 0.4419\n",
      "Epoch 184/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5073 - val_accuracy: 0.7336 - val_loss: 0.4420\n",
      "Epoch 185/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.5134 - val_accuracy: 0.7336 - val_loss: 0.4413\n",
      "Epoch 186/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7276 - loss: 0.5178 - val_accuracy: 0.7336 - val_loss: 0.4410\n",
      "Epoch 187/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7264 - loss: 0.5149 - val_accuracy: 0.7336 - val_loss: 0.4408\n",
      "Epoch 188/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5088 - val_accuracy: 0.7336 - val_loss: 0.4406\n",
      "Epoch 189/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.5035 - val_accuracy: 0.7336 - val_loss: 0.4406\n",
      "Epoch 190/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5050 - val_accuracy: 0.7336 - val_loss: 0.4402\n",
      "Epoch 191/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.5096 - val_accuracy: 0.7336 - val_loss: 0.4400\n",
      "Epoch 192/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5171 - val_accuracy: 0.7336 - val_loss: 0.4406\n",
      "Epoch 193/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.5084 - val_accuracy: 0.7336 - val_loss: 0.4403\n",
      "Epoch 194/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7406 - loss: 0.5228 - val_accuracy: 0.7336 - val_loss: 0.4407\n",
      "Epoch 195/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7245 - loss: 0.5219 - val_accuracy: 0.7336 - val_loss: 0.4414\n",
      "Epoch 196/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7250 - loss: 0.5076 - val_accuracy: 0.7336 - val_loss: 0.4414\n",
      "Epoch 197/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7461 - loss: 0.4943 - val_accuracy: 0.7336 - val_loss: 0.4412\n",
      "Epoch 198/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.5213 - val_accuracy: 0.7336 - val_loss: 0.4415\n",
      "Epoch 199/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7309 - loss: 0.5159 - val_accuracy: 0.7336 - val_loss: 0.4416\n",
      "Epoch 200/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.4984 - val_accuracy: 0.7336 - val_loss: 0.4411\n",
      "Epoch 201/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7231 - loss: 0.5141 - val_accuracy: 0.7336 - val_loss: 0.4409\n",
      "Epoch 202/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.5114 - val_accuracy: 0.7336 - val_loss: 0.4408\n",
      "Epoch 203/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.5093 - val_accuracy: 0.7336 - val_loss: 0.4409\n",
      "Epoch 204/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5153 - val_accuracy: 0.7336 - val_loss: 0.4410\n",
      "Epoch 205/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7326 - loss: 0.5101 - val_accuracy: 0.7336 - val_loss: 0.4408\n",
      "Epoch 206/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7215 - loss: 0.5114 - val_accuracy: 0.7336 - val_loss: 0.4402\n",
      "Epoch 207/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5095 - val_accuracy: 0.7336 - val_loss: 0.4400\n",
      "Epoch 208/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.5107 - val_accuracy: 0.7336 - val_loss: 0.4395\n",
      "Epoch 209/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: 0.5224 - val_accuracy: 0.7336 - val_loss: 0.4395\n",
      "Epoch 210/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7274 - loss: 0.5085 - val_accuracy: 0.7336 - val_loss: 0.4392\n",
      "Epoch 211/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5244 - val_accuracy: 0.7336 - val_loss: 0.4394\n",
      "Epoch 212/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7495 - loss: 0.5005 - val_accuracy: 0.7336 - val_loss: 0.4394\n",
      "Epoch 213/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7476 - loss: 0.4999 - val_accuracy: 0.7336 - val_loss: 0.4394\n",
      "Epoch 214/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.4995 - val_accuracy: 0.7336 - val_loss: 0.4394\n",
      "Epoch 215/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7260 - loss: 0.5249 - val_accuracy: 0.7336 - val_loss: 0.4395\n",
      "Epoch 216/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.5098 - val_accuracy: 0.7336 - val_loss: 0.4394\n",
      "Epoch 217/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7459 - loss: 0.5008 - val_accuracy: 0.7336 - val_loss: 0.4394\n",
      "Epoch 218/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: 0.4933 - val_accuracy: 0.7336 - val_loss: 0.4391\n",
      "Epoch 219/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.5129 - val_accuracy: 0.7336 - val_loss: 0.4393\n",
      "Epoch 220/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7390 - loss: 0.4997 - val_accuracy: 0.7336 - val_loss: 0.4393\n",
      "Epoch 221/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.5015 - val_accuracy: 0.7336 - val_loss: 0.4395\n",
      "Epoch 222/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 0.4843 - val_accuracy: 0.7336 - val_loss: 0.4392\n",
      "Epoch 223/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5059 - val_accuracy: 0.7336 - val_loss: 0.4391\n",
      "Epoch 224/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7248 - loss: 0.5151 - val_accuracy: 0.7336 - val_loss: 0.4390\n",
      "Epoch 225/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5056 - val_accuracy: 0.7336 - val_loss: 0.4387\n",
      "Epoch 226/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7303 - loss: 0.5169 - val_accuracy: 0.7336 - val_loss: 0.4387\n",
      "Epoch 227/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7208 - loss: 0.5079 - val_accuracy: 0.7336 - val_loss: 0.4384\n",
      "Epoch 228/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.5079 - val_accuracy: 0.7336 - val_loss: 0.4386\n",
      "Epoch 229/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.5151 - val_accuracy: 0.7336 - val_loss: 0.4387\n",
      "Epoch 230/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.5261 - val_accuracy: 0.7336 - val_loss: 0.4385\n",
      "Epoch 231/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.5143 - val_accuracy: 0.7336 - val_loss: 0.4383\n",
      "Epoch 232/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.5163 - val_accuracy: 0.7336 - val_loss: 0.4383\n",
      "Epoch 233/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.5019 - val_accuracy: 0.7336 - val_loss: 0.4381\n",
      "Epoch 234/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.5110 - val_accuracy: 0.7336 - val_loss: 0.4381\n",
      "Epoch 235/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5025 - val_accuracy: 0.7336 - val_loss: 0.4378\n",
      "Epoch 236/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.5105 - val_accuracy: 0.7336 - val_loss: 0.4376\n",
      "Epoch 237/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.4997 - val_accuracy: 0.7336 - val_loss: 0.4372\n",
      "Epoch 238/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.4960 - val_accuracy: 0.7336 - val_loss: 0.4372\n",
      "Epoch 239/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5036 - val_accuracy: 0.7336 - val_loss: 0.4373\n",
      "Epoch 240/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.5076 - val_accuracy: 0.7336 - val_loss: 0.4373\n",
      "Epoch 241/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5036 - val_accuracy: 0.7336 - val_loss: 0.4371\n",
      "Epoch 242/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5103 - val_accuracy: 0.7336 - val_loss: 0.4372\n",
      "Epoch 243/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5067 - val_accuracy: 0.7336 - val_loss: 0.4373\n",
      "Epoch 244/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.4988 - val_accuracy: 0.7336 - val_loss: 0.4370\n",
      "Epoch 245/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.5088 - val_accuracy: 0.7336 - val_loss: 0.4371\n",
      "Epoch 246/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7251 - loss: 0.5084 - val_accuracy: 0.7336 - val_loss: 0.4370\n",
      "Epoch 247/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7289 - loss: 0.5129 - val_accuracy: 0.7336 - val_loss: 0.4373\n",
      "Epoch 248/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.5055 - val_accuracy: 0.7336 - val_loss: 0.4374\n",
      "Epoch 249/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7450 - loss: 0.4970 - val_accuracy: 0.7336 - val_loss: 0.4373\n",
      "Epoch 250/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.5007 - val_accuracy: 0.7336 - val_loss: 0.4373\n",
      "Epoch 251/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.4887 - val_accuracy: 0.7336 - val_loss: 0.4371\n",
      "Epoch 252/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7349 - loss: 0.5077 - val_accuracy: 0.7336 - val_loss: 0.4368\n",
      "Epoch 253/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.4974 - val_accuracy: 0.7336 - val_loss: 0.4367\n",
      "Epoch 254/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5059 - val_accuracy: 0.7336 - val_loss: 0.4366\n",
      "Epoch 255/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.4943 - val_accuracy: 0.7336 - val_loss: 0.4363\n",
      "Epoch 256/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7403 - loss: 0.4987 - val_accuracy: 0.7336 - val_loss: 0.4363\n",
      "Epoch 257/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7439 - loss: 0.4984 - val_accuracy: 0.7336 - val_loss: 0.4363\n",
      "Epoch 258/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.5126 - val_accuracy: 0.7336 - val_loss: 0.4364\n",
      "Epoch 259/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7404 - loss: 0.5048 - val_accuracy: 0.7336 - val_loss: 0.4365\n",
      "Epoch 260/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7283 - loss: 0.5069 - val_accuracy: 0.7336 - val_loss: 0.4364\n",
      "Epoch 261/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5057 - val_accuracy: 0.7336 - val_loss: 0.4366\n",
      "Epoch 262/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7189 - loss: 0.5129 - val_accuracy: 0.7336 - val_loss: 0.4364\n",
      "Epoch 263/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.4999 - val_accuracy: 0.7336 - val_loss: 0.4363\n",
      "Epoch 264/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7294 - loss: 0.5164 - val_accuracy: 0.7336 - val_loss: 0.4365\n",
      "Epoch 265/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5175 - val_accuracy: 0.7336 - val_loss: 0.4368\n",
      "Epoch 266/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7257 - loss: 0.5104 - val_accuracy: 0.7336 - val_loss: 0.4367\n",
      "Epoch 267/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.5137 - val_accuracy: 0.7336 - val_loss: 0.4367\n",
      "Epoch 268/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.5002 - val_accuracy: 0.7336 - val_loss: 0.4365\n",
      "Epoch 269/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5076 - val_accuracy: 0.7336 - val_loss: 0.4366\n",
      "Epoch 270/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7259 - loss: 0.5096 - val_accuracy: 0.7336 - val_loss: 0.4364\n",
      "Epoch 271/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7310 - loss: 0.5007 - val_accuracy: 0.7336 - val_loss: 0.4363\n",
      "Epoch 272/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7240 - loss: 0.5151 - val_accuracy: 0.7336 - val_loss: 0.4365\n",
      "Epoch 273/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7423 - loss: 0.4864 - val_accuracy: 0.7336 - val_loss: 0.4365\n",
      "Epoch 274/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5087 - val_accuracy: 0.7336 - val_loss: 0.4364\n",
      "Epoch 275/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7359 - loss: 0.4959 - val_accuracy: 0.7336 - val_loss: 0.4363\n",
      "Epoch 276/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.5050 - val_accuracy: 0.7336 - val_loss: 0.4364\n",
      "Epoch 277/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.4983 - val_accuracy: 0.7336 - val_loss: 0.4364\n",
      "Epoch 278/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.4939 - val_accuracy: 0.7336 - val_loss: 0.4362\n",
      "Epoch 279/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.5024 - val_accuracy: 0.7336 - val_loss: 0.4361\n",
      "Epoch 280/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7321 - loss: 0.4961 - val_accuracy: 0.7336 - val_loss: 0.4355\n",
      "Epoch 281/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.5050 - val_accuracy: 0.7336 - val_loss: 0.4357\n",
      "Epoch 282/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5056 - val_accuracy: 0.7336 - val_loss: 0.4358\n",
      "Epoch 283/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 0.5143 - val_accuracy: 0.7336 - val_loss: 0.4356\n",
      "Epoch 284/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.5039 - val_accuracy: 0.7336 - val_loss: 0.4353\n",
      "Epoch 285/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.5015 - val_accuracy: 0.7336 - val_loss: 0.4352\n",
      "Epoch 286/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7381 - loss: 0.5024 - val_accuracy: 0.7336 - val_loss: 0.4353\n",
      "Epoch 287/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.4913 - val_accuracy: 0.7336 - val_loss: 0.4350\n",
      "Epoch 288/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7224 - loss: 0.5127 - val_accuracy: 0.7336 - val_loss: 0.4352\n",
      "Epoch 289/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7282 - loss: 0.4996 - val_accuracy: 0.7336 - val_loss: 0.4352\n",
      "Epoch 290/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7253 - loss: 0.5044 - val_accuracy: 0.7336 - val_loss: 0.4350\n",
      "Epoch 291/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 0.4915 - val_accuracy: 0.7336 - val_loss: 0.4348\n",
      "Epoch 292/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5021 - val_accuracy: 0.7336 - val_loss: 0.4346\n",
      "Epoch 293/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7468 - loss: 0.4913 - val_accuracy: 0.7336 - val_loss: 0.4347\n",
      "Epoch 294/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.4897 - val_accuracy: 0.7336 - val_loss: 0.4348\n",
      "Epoch 295/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.4908 - val_accuracy: 0.7336 - val_loss: 0.4351\n",
      "Epoch 296/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.4953 - val_accuracy: 0.7336 - val_loss: 0.4351\n",
      "Epoch 297/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.4935 - val_accuracy: 0.7336 - val_loss: 0.4355\n",
      "Epoch 298/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.5009 - val_accuracy: 0.7336 - val_loss: 0.4355\n",
      "Epoch 299/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.4896 - val_accuracy: 0.7336 - val_loss: 0.4352\n",
      "Epoch 300/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7287 - loss: 0.5045 - val_accuracy: 0.7336 - val_loss: 0.4350\n",
      "Epoch 301/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.5042 - val_accuracy: 0.7336 - val_loss: 0.4349\n",
      "Epoch 302/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.4903 - val_accuracy: 0.7336 - val_loss: 0.4349\n",
      "Epoch 303/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.5090 - val_accuracy: 0.7336 - val_loss: 0.4348\n",
      "Epoch 304/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.4917 - val_accuracy: 0.7336 - val_loss: 0.4346\n",
      "Epoch 305/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7420 - loss: 0.4922 - val_accuracy: 0.7336 - val_loss: 0.4346\n",
      "Epoch 306/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.4906 - val_accuracy: 0.7336 - val_loss: 0.4344\n",
      "Epoch 307/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7361 - loss: 0.5041 - val_accuracy: 0.7336 - val_loss: 0.4345\n",
      "Epoch 308/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7225 - loss: 0.5079 - val_accuracy: 0.7336 - val_loss: 0.4344\n",
      "Epoch 309/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7375 - loss: 0.4978 - val_accuracy: 0.7336 - val_loss: 0.4345\n",
      "Epoch 310/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.4977 - val_accuracy: 0.7336 - val_loss: 0.4348\n",
      "Epoch 311/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7283 - loss: 0.4994 - val_accuracy: 0.7336 - val_loss: 0.4349\n",
      "Epoch 312/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7431 - loss: 0.4942 - val_accuracy: 0.7336 - val_loss: 0.4346\n",
      "Epoch 313/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.4826 - val_accuracy: 0.7336 - val_loss: 0.4343\n",
      "Epoch 314/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.4902 - val_accuracy: 0.7336 - val_loss: 0.4341\n",
      "Epoch 315/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.5016 - val_accuracy: 0.7336 - val_loss: 0.4344\n",
      "Epoch 316/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5024 - val_accuracy: 0.7336 - val_loss: 0.4345\n",
      "Epoch 317/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.4945 - val_accuracy: 0.7336 - val_loss: 0.4344\n",
      "Epoch 318/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7446 - loss: 0.4860 - val_accuracy: 0.7336 - val_loss: 0.4344\n",
      "Epoch 319/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5025 - val_accuracy: 0.7336 - val_loss: 0.4345\n",
      "Epoch 320/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.4988 - val_accuracy: 0.7336 - val_loss: 0.4343\n",
      "Epoch 321/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.5005 - val_accuracy: 0.7336 - val_loss: 0.4345\n",
      "Epoch 322/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.5080 - val_accuracy: 0.7336 - val_loss: 0.4345\n",
      "Epoch 323/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5001 - val_accuracy: 0.7336 - val_loss: 0.4343\n",
      "Epoch 324/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.5023 - val_accuracy: 0.7336 - val_loss: 0.4342\n",
      "Epoch 325/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7278 - loss: 0.4911 - val_accuracy: 0.7336 - val_loss: 0.4337\n",
      "Epoch 326/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.4887 - val_accuracy: 0.7336 - val_loss: 0.4335\n",
      "Epoch 327/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7254 - loss: 0.5074 - val_accuracy: 0.7336 - val_loss: 0.4334\n",
      "Epoch 328/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7368 - loss: 0.4993 - val_accuracy: 0.7336 - val_loss: 0.4331\n",
      "Epoch 329/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7359 - loss: 0.4837 - val_accuracy: 0.7336 - val_loss: 0.4328\n",
      "Epoch 330/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: 0.5037 - val_accuracy: 0.7336 - val_loss: 0.4330\n",
      "Epoch 331/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.4930 - val_accuracy: 0.7336 - val_loss: 0.4327\n",
      "Epoch 332/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.4898 - val_accuracy: 0.7336 - val_loss: 0.4325\n",
      "Epoch 333/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.4886 - val_accuracy: 0.7336 - val_loss: 0.4323\n",
      "Epoch 334/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7229 - loss: 0.5057 - val_accuracy: 0.7336 - val_loss: 0.4323\n",
      "Epoch 335/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7253 - loss: 0.4981 - val_accuracy: 0.7336 - val_loss: 0.4324\n",
      "Epoch 336/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.4995 - val_accuracy: 0.7336 - val_loss: 0.4327\n",
      "Epoch 337/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.5004 - val_accuracy: 0.7336 - val_loss: 0.4326\n",
      "Epoch 338/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.4799 - val_accuracy: 0.7336 - val_loss: 0.4325\n",
      "Epoch 339/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.4999 - val_accuracy: 0.7336 - val_loss: 0.4326\n",
      "Epoch 340/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7375 - loss: 0.4914 - val_accuracy: 0.7336 - val_loss: 0.4327\n",
      "Epoch 341/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.4885 - val_accuracy: 0.7336 - val_loss: 0.4328\n",
      "Epoch 342/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.4940 - val_accuracy: 0.7336 - val_loss: 0.4325\n",
      "Epoch 343/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7372 - loss: 0.4817 - val_accuracy: 0.7336 - val_loss: 0.4325\n",
      "Epoch 344/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.4820 - val_accuracy: 0.7336 - val_loss: 0.4323\n",
      "Epoch 345/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.4856 - val_accuracy: 0.7336 - val_loss: 0.4321\n",
      "Epoch 346/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.4950 - val_accuracy: 0.7336 - val_loss: 0.4320\n",
      "Epoch 347/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7370 - loss: 0.4848 - val_accuracy: 0.7336 - val_loss: 0.4321\n",
      "Epoch 348/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.4995 - val_accuracy: 0.7336 - val_loss: 0.4323\n",
      "Epoch 349/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7278 - loss: 0.4919 - val_accuracy: 0.7336 - val_loss: 0.4322\n",
      "Epoch 350/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.4878 - val_accuracy: 0.7336 - val_loss: 0.4320\n",
      "Epoch 351/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.4839 - val_accuracy: 0.7336 - val_loss: 0.4320\n",
      "Epoch 352/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7213 - loss: 0.5051 - val_accuracy: 0.7336 - val_loss: 0.4319\n",
      "Epoch 353/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.4850 - val_accuracy: 0.7336 - val_loss: 0.4318\n",
      "Epoch 354/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.4943 - val_accuracy: 0.7336 - val_loss: 0.4319\n",
      "Epoch 355/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.5023 - val_accuracy: 0.7336 - val_loss: 0.4320\n",
      "Epoch 356/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.5126 - val_accuracy: 0.7336 - val_loss: 0.4322\n",
      "Epoch 357/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.4947 - val_accuracy: 0.7336 - val_loss: 0.4322\n",
      "Epoch 358/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.4988 - val_accuracy: 0.7336 - val_loss: 0.4322\n",
      "Epoch 359/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7303 - loss: 0.4910 - val_accuracy: 0.7336 - val_loss: 0.4320\n",
      "Epoch 360/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.4860 - val_accuracy: 0.7336 - val_loss: 0.4319\n",
      "Epoch 361/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7237 - loss: 0.5073 - val_accuracy: 0.7336 - val_loss: 0.4319\n",
      "Epoch 362/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.4862 - val_accuracy: 0.7336 - val_loss: 0.4318\n",
      "Epoch 363/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7226 - loss: 0.5028 - val_accuracy: 0.7336 - val_loss: 0.4316\n",
      "Epoch 364/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.4886 - val_accuracy: 0.7336 - val_loss: 0.4315\n",
      "Epoch 365/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7294 - loss: 0.4988 - val_accuracy: 0.7336 - val_loss: 0.4313\n",
      "Epoch 366/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.4944 - val_accuracy: 0.7336 - val_loss: 0.4314\n",
      "Epoch 367/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.4912 - val_accuracy: 0.7336 - val_loss: 0.4313\n",
      "Epoch 368/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.4929 - val_accuracy: 0.7336 - val_loss: 0.4313\n",
      "Epoch 369/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.4971 - val_accuracy: 0.7336 - val_loss: 0.4313\n",
      "Epoch 370/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7427 - loss: 0.4806 - val_accuracy: 0.7336 - val_loss: 0.4312\n",
      "Epoch 371/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.4972 - val_accuracy: 0.7336 - val_loss: 0.4313\n",
      "Epoch 372/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7237 - loss: 0.4979 - val_accuracy: 0.7336 - val_loss: 0.4312\n",
      "Epoch 373/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.4866 - val_accuracy: 0.7336 - val_loss: 0.4310\n",
      "Epoch 374/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7372 - loss: 0.4910 - val_accuracy: 0.7336 - val_loss: 0.4312\n",
      "Epoch 375/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7236 - loss: 0.5020 - val_accuracy: 0.7336 - val_loss: 0.4312\n",
      "Epoch 376/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.4964 - val_accuracy: 0.7336 - val_loss: 0.4312\n",
      "Epoch 377/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7456 - loss: 0.4860 - val_accuracy: 0.7336 - val_loss: 0.4310\n",
      "Epoch 378/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7460 - loss: 0.4774 - val_accuracy: 0.7336 - val_loss: 0.4310\n",
      "Epoch 379/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.4897 - val_accuracy: 0.7336 - val_loss: 0.4309\n",
      "Epoch 380/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.4951 - val_accuracy: 0.7336 - val_loss: 0.4307\n",
      "Epoch 381/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.4966 - val_accuracy: 0.7336 - val_loss: 0.4308\n",
      "Epoch 382/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.4765 - val_accuracy: 0.7336 - val_loss: 0.4305\n",
      "Epoch 383/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.4769 - val_accuracy: 0.7336 - val_loss: 0.4305\n",
      "Epoch 384/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.4951 - val_accuracy: 0.7336 - val_loss: 0.4303\n",
      "Epoch 385/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.4827 - val_accuracy: 0.7336 - val_loss: 0.4303\n",
      "Epoch 386/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7261 - loss: 0.4937 - val_accuracy: 0.7336 - val_loss: 0.4304\n",
      "Epoch 387/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.4975 - val_accuracy: 0.7336 - val_loss: 0.4303\n",
      "Epoch 388/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.4871 - val_accuracy: 0.7336 - val_loss: 0.4301\n",
      "Epoch 389/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7332 - loss: 0.4826 - val_accuracy: 0.7336 - val_loss: 0.4298\n",
      "Epoch 390/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7185 - loss: 0.4993 - val_accuracy: 0.7336 - val_loss: 0.4301\n",
      "Epoch 391/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7384 - loss: 0.4849 - val_accuracy: 0.7336 - val_loss: 0.4302\n",
      "Epoch 392/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7412 - loss: 0.4865 - val_accuracy: 0.7336 - val_loss: 0.4304\n",
      "Epoch 393/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7345 - loss: 0.4926 - val_accuracy: 0.7336 - val_loss: 0.4305\n",
      "Epoch 394/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7243 - loss: 0.4920 - val_accuracy: 0.7336 - val_loss: 0.4304\n",
      "Epoch 395/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7426 - loss: 0.4838 - val_accuracy: 0.7336 - val_loss: 0.4304\n",
      "Epoch 396/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.4911 - val_accuracy: 0.7336 - val_loss: 0.4303\n",
      "Epoch 397/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.4924 - val_accuracy: 0.7336 - val_loss: 0.4301\n",
      "Epoch 398/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5063 - val_accuracy: 0.7336 - val_loss: 0.4302\n",
      "Epoch 399/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7297 - loss: 0.4868 - val_accuracy: 0.7336 - val_loss: 0.4301\n",
      "Epoch 400/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7520 - loss: 0.4754 - val_accuracy: 0.7336 - val_loss: 0.4301\n",
      "Epoch 401/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7294 - loss: 0.4897 - val_accuracy: 0.7336 - val_loss: 0.4300\n",
      "Epoch 402/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7401 - loss: 0.4815 - val_accuracy: 0.7336 - val_loss: 0.4298\n",
      "Epoch 403/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.4940 - val_accuracy: 0.7336 - val_loss: 0.4300\n",
      "Epoch 404/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7264 - loss: 0.4888 - val_accuracy: 0.7336 - val_loss: 0.4298\n",
      "Epoch 405/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.5068 - val_accuracy: 0.7336 - val_loss: 0.4300\n",
      "Epoch 406/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.4871 - val_accuracy: 0.7336 - val_loss: 0.4299\n",
      "Epoch 407/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7435 - loss: 0.4826 - val_accuracy: 0.7336 - val_loss: 0.4300\n",
      "Epoch 408/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.4889 - val_accuracy: 0.7336 - val_loss: 0.4299\n",
      "Epoch 409/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.4926 - val_accuracy: 0.7336 - val_loss: 0.4301\n",
      "Epoch 410/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.4850 - val_accuracy: 0.7336 - val_loss: 0.4302\n",
      "Epoch 411/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.4884 - val_accuracy: 0.7336 - val_loss: 0.4299\n",
      "Epoch 412/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7378 - loss: 0.4917 - val_accuracy: 0.7336 - val_loss: 0.4300\n",
      "Epoch 413/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7539 - loss: 0.4727 - val_accuracy: 0.7336 - val_loss: 0.4303\n",
      "Epoch 414/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.4894 - val_accuracy: 0.7336 - val_loss: 0.4301\n",
      "Epoch 415/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7435 - loss: 0.4831 - val_accuracy: 0.7336 - val_loss: 0.4298\n",
      "Epoch 416/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.4848 - val_accuracy: 0.7336 - val_loss: 0.4297\n",
      "Epoch 417/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.4884 - val_accuracy: 0.7336 - val_loss: 0.4296\n",
      "Epoch 418/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.4809 - val_accuracy: 0.7336 - val_loss: 0.4293\n",
      "Epoch 419/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.4846 - val_accuracy: 0.7336 - val_loss: 0.4290\n",
      "Epoch 420/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7236 - loss: 0.5090 - val_accuracy: 0.7336 - val_loss: 0.4289\n",
      "Epoch 421/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.4952 - val_accuracy: 0.7336 - val_loss: 0.4290\n",
      "Epoch 422/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7190 - loss: 0.5046 - val_accuracy: 0.7336 - val_loss: 0.4291\n",
      "Epoch 423/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: 0.4987 - val_accuracy: 0.7336 - val_loss: 0.4290\n",
      "Epoch 424/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: 0.4860 - val_accuracy: 0.7336 - val_loss: 0.4289\n",
      "Epoch 425/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7375 - loss: 0.4780 - val_accuracy: 0.7336 - val_loss: 0.4288\n",
      "Epoch 426/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.4865 - val_accuracy: 0.7336 - val_loss: 0.4289\n",
      "Epoch 427/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7196 - loss: 0.4969 - val_accuracy: 0.7336 - val_loss: 0.4291\n",
      "Epoch 428/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.4970 - val_accuracy: 0.7336 - val_loss: 0.4290\n",
      "Epoch 429/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.4844 - val_accuracy: 0.7336 - val_loss: 0.4289\n",
      "Epoch 430/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7225 - loss: 0.5029 - val_accuracy: 0.7336 - val_loss: 0.4290\n",
      "Epoch 431/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7308 - loss: 0.4887 - val_accuracy: 0.7336 - val_loss: 0.4287\n",
      "Epoch 432/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5119 - val_accuracy: 0.7336 - val_loss: 0.4289\n",
      "Epoch 433/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7228 - loss: 0.5008 - val_accuracy: 0.7336 - val_loss: 0.4287\n",
      "Epoch 434/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7358 - loss: 0.4834 - val_accuracy: 0.7336 - val_loss: 0.4286\n",
      "Epoch 435/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7322 - loss: 0.4881 - val_accuracy: 0.7336 - val_loss: 0.4286\n",
      "Epoch 436/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7311 - loss: 0.4978 - val_accuracy: 0.7336 - val_loss: 0.4287\n",
      "Epoch 437/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.4790 - val_accuracy: 0.7336 - val_loss: 0.4287\n",
      "Epoch 438/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.4955 - val_accuracy: 0.7336 - val_loss: 0.4289\n",
      "Epoch 439/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7265 - loss: 0.4828 - val_accuracy: 0.7336 - val_loss: 0.4287\n",
      "Epoch 440/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7404 - loss: 0.4829 - val_accuracy: 0.7336 - val_loss: 0.4287\n",
      "Epoch 441/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.4902 - val_accuracy: 0.7336 - val_loss: 0.4285\n",
      "Epoch 442/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.4895 - val_accuracy: 0.7336 - val_loss: 0.4281\n",
      "Epoch 443/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7340 - loss: 0.4846 - val_accuracy: 0.7336 - val_loss: 0.4281\n",
      "Epoch 444/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 0.4736 - val_accuracy: 0.7336 - val_loss: 0.4281\n",
      "Epoch 445/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.4769 - val_accuracy: 0.7336 - val_loss: 0.4282\n",
      "Epoch 446/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.4710 - val_accuracy: 0.7336 - val_loss: 0.4281\n",
      "Epoch 447/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.4817 - val_accuracy: 0.7336 - val_loss: 0.4279\n",
      "Epoch 448/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.4843 - val_accuracy: 0.7336 - val_loss: 0.4280\n",
      "Epoch 449/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.4797 - val_accuracy: 0.7336 - val_loss: 0.4282\n",
      "Epoch 450/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.4850 - val_accuracy: 0.7336 - val_loss: 0.4282\n",
      "Epoch 451/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.4806 - val_accuracy: 0.7336 - val_loss: 0.4282\n",
      "Epoch 452/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.4949 - val_accuracy: 0.7336 - val_loss: 0.4280\n",
      "Epoch 453/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.4943 - val_accuracy: 0.7336 - val_loss: 0.4279\n",
      "Epoch 454/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.4996 - val_accuracy: 0.7336 - val_loss: 0.4280\n",
      "Epoch 455/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7385 - loss: 0.4762 - val_accuracy: 0.7336 - val_loss: 0.4278\n",
      "Epoch 456/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.4817 - val_accuracy: 0.7336 - val_loss: 0.4276\n",
      "Epoch 457/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.4836 - val_accuracy: 0.7336 - val_loss: 0.4272\n",
      "Epoch 458/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7344 - loss: 0.4839 - val_accuracy: 0.7336 - val_loss: 0.4272\n",
      "Epoch 459/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.4889 - val_accuracy: 0.7336 - val_loss: 0.4272\n",
      "Epoch 460/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.4782 - val_accuracy: 0.7336 - val_loss: 0.4271\n",
      "Epoch 461/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7312 - loss: 0.4765 - val_accuracy: 0.7336 - val_loss: 0.4269\n",
      "Epoch 462/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7290 - loss: 0.4890 - val_accuracy: 0.7336 - val_loss: 0.4268\n",
      "Epoch 463/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.4793 - val_accuracy: 0.7336 - val_loss: 0.4268\n",
      "Epoch 464/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.4760 - val_accuracy: 0.7336 - val_loss: 0.4269\n",
      "Epoch 465/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.4910 - val_accuracy: 0.7336 - val_loss: 0.4267\n",
      "Epoch 466/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7331 - loss: 0.5007 - val_accuracy: 0.7336 - val_loss: 0.4269\n",
      "Epoch 467/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.4892 - val_accuracy: 0.7336 - val_loss: 0.4266\n",
      "Epoch 468/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7266 - loss: 0.4912 - val_accuracy: 0.7336 - val_loss: 0.4267\n",
      "Epoch 469/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7295 - loss: 0.4919 - val_accuracy: 0.7336 - val_loss: 0.4268\n",
      "Epoch 470/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7297 - loss: 0.4892 - val_accuracy: 0.7336 - val_loss: 0.4269\n",
      "Epoch 471/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.4827 - val_accuracy: 0.7336 - val_loss: 0.4268\n",
      "Epoch 472/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.4892 - val_accuracy: 0.7336 - val_loss: 0.4270\n",
      "Epoch 473/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.4817 - val_accuracy: 0.7336 - val_loss: 0.4269\n",
      "Epoch 474/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7264 - loss: 0.4847 - val_accuracy: 0.7336 - val_loss: 0.4269\n",
      "Epoch 475/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.4876 - val_accuracy: 0.7336 - val_loss: 0.4268\n",
      "Epoch 476/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7279 - loss: 0.4949 - val_accuracy: 0.7336 - val_loss: 0.4268\n",
      "Epoch 477/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7220 - loss: 0.4953 - val_accuracy: 0.7336 - val_loss: 0.4268\n",
      "Epoch 478/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.4899 - val_accuracy: 0.7336 - val_loss: 0.4267\n",
      "Epoch 479/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7352 - loss: 0.4871 - val_accuracy: 0.7336 - val_loss: 0.4267\n",
      "Epoch 480/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.4693 - val_accuracy: 0.7336 - val_loss: 0.4267\n",
      "Epoch 481/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7317 - loss: 0.4928 - val_accuracy: 0.7336 - val_loss: 0.4269\n",
      "Epoch 482/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7252 - loss: 0.4809 - val_accuracy: 0.7336 - val_loss: 0.4266\n",
      "Epoch 483/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.4706 - val_accuracy: 0.7336 - val_loss: 0.4266\n",
      "Epoch 484/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7554 - loss: 0.4685 - val_accuracy: 0.7336 - val_loss: 0.4265\n",
      "Epoch 485/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.4941 - val_accuracy: 0.7336 - val_loss: 0.4264\n",
      "Epoch 486/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.4690 - val_accuracy: 0.7336 - val_loss: 0.4265\n",
      "Epoch 487/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.4807 - val_accuracy: 0.7336 - val_loss: 0.4266\n",
      "Epoch 488/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: 0.4837 - val_accuracy: 0.7336 - val_loss: 0.4266\n",
      "Epoch 489/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.4874 - val_accuracy: 0.7336 - val_loss: 0.4267\n",
      "Epoch 490/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.4883 - val_accuracy: 0.7336 - val_loss: 0.4266\n",
      "Epoch 491/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.4721 - val_accuracy: 0.7336 - val_loss: 0.4262\n",
      "Epoch 492/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7330 - loss: 0.4772 - val_accuracy: 0.7336 - val_loss: 0.4261\n",
      "Epoch 493/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7291 - loss: 0.4902 - val_accuracy: 0.7336 - val_loss: 0.4261\n",
      "Epoch 494/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.4751 - val_accuracy: 0.7336 - val_loss: 0.4259\n",
      "Epoch 495/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.4824 - val_accuracy: 0.7336 - val_loss: 0.4261\n",
      "Epoch 496/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7421 - loss: 0.4775 - val_accuracy: 0.7336 - val_loss: 0.4260\n",
      "Epoch 497/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7354 - loss: 0.4859 - val_accuracy: 0.7336 - val_loss: 0.4261\n",
      "Epoch 498/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7424 - loss: 0.4686 - val_accuracy: 0.7336 - val_loss: 0.4260\n",
      "Epoch 499/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7341 - loss: 0.4841 - val_accuracy: 0.7336 - val_loss: 0.4261\n",
      "Epoch 500/500\n",
      "\u001b[1m159/159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.4835 - val_accuracy: 0.7336 - val_loss: 0.4262\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs = epochs, #experiment 200 was much, graph showed 25 could be ideal\n",
    "    validation_split=validation_split,\n",
    "    batch_size = batch_size,\n",
    "    verbose = 1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plots the training loss and accuracy curves from a Keras History object.\n",
    "\n",
    "    Args:\n",
    "        history: The History object returned by model.fit().\n",
    "    \"\"\"\n",
    "    # --- Plot Training & Validation Loss ---\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1) # 1 row, 2 columns, first subplot\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    if 'val_loss' in history.history: # Check if validation loss is available\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # --- Plot Training & Validation Accuracy ---\n",
    "    plt.subplot(1, 2, 2) # 1 row, 2 columns, second subplot\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    if 'val_accuracy' in history.history: # Check if validation accuracy is available\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout() # Adjust layout to prevent overlapping titles/labels\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7366 - loss: 0.4531\n",
      "Loss:  0.45823535323143005\n",
      "Accuracy:  0.7341862320899963\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85      1033\n",
      "           1       0.00      0.00      0.00       374\n",
      "\n",
      "    accuracy                           0.73      1407\n",
      "   macro avg       0.37      0.50      0.42      1407\n",
      "weighted avg       0.54      0.73      0.62      1407\n",
      "\n",
      "\n",
      "Confusion Matrix (Raw Counts):\n",
      "[[1033    0]\n",
      " [ 374    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Linos\\Documents\\Coding_practice\\Dirbtinis Intelektas ir Python\\Telecommunications_bussiness_analysis\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "y_pred_probabilities = model.predict(X_test) # Get probability outputs\n",
    "y_pred = (y_pred_probabilities > 0.5).astype(int) # Convert probabilities to class labels (integer class indices)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Raw Counts):\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT with:\n",
    "#     - Using a wider and narrower sets\n",
    "#     - Number of hidden layers\n",
    "#     - Number of neurons per hidden layer\n",
    "#     - Activation functions (ReLU, LeakyReLU, tanh, sigmoid - for hidden layers)\n",
    "#     - Optimizer (adam, sgd, rmsprop, etc.)\n",
    "#     - Learning rate (for the optimizer)\n",
    "#     - Batch size\n",
    "#     - Number of epochs\n",
    "#     - Regularization techniques (Dropout, L1/L2 regularization if overfitting)\n",
    "#     - Different preprocessing methods (imputation, scaling, feature engineering)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
